# Hospital Readmission Prediction for Diabetic Patients

Predicting 30â€‘day hospital readmissions among diabetic patients using statistical and machineâ€‘learning approaches in R.

**Author:** Ugo  
**Date:** August 2025

---

## ðŸ“Œ Project Overview

This repository contains the full technical and statistical workflow for building and evaluating models to predict nearâ€‘term hospital readmission in diabetic patients. The analysis is implemented in R via an R Markdown report, with reproducible steps for data preparation, exploratory analysis, feature engineering, model development, and evaluation.

**Core approaches:** anova, auc, confusion matrix, logistic regression, precision, random forest, recall, roc.

---

## ðŸ—‚ Repository Structure

```text
.
â”œâ”€â”€ data/                  # (optional) Raw/processed data (excluded from git if sensitive)
â”œâ”€â”€ scripts/               # Utility R scripts (if you split the Rmd later)
â”œâ”€â”€ models/                # Saved model objects / tuning artifacts
â”œâ”€â”€ figs/                  # Exported plots (ROC, PR, importances)
â”œâ”€â”€ reports/               # Rendered outputs (HTML/PDF/Word)
â”œâ”€â”€ docs/                  # Additional methodological notes
â”œâ”€â”€ Hospital Readmission Prediction for Diabetic Patients _Ugo Raw.Rmd
â””â”€â”€ README.md
```

> Tip: Add `data/` and any secrets to `.gitignore` if needed.

---

## ðŸ”§ Environment & Setup

- **R version:** 4.3+ recommended  
- **RStudio:** 2023.12+ recommended  
- **Primary packages:**  
- `Hmisc`
- `MASS`
- `assertr`
- `caret`
- `class`
- `corrplot`
- `doParallel`
- `dplyr`
- `flextable`
- `ggplot2`
- `ggpubr`
- `knitr`
- `lme4`
- `lubridate`
- `officer`
- `openxlsx`
- `pROC`
- `patchwork`
- `randomForest`
- `ranger`
- `readr`
- `readxl`
- `tidyverse`
- `vip`

### Install packages
You can install any missing packages with:
```r
required_pkgs <- c("Hmisc", "MASS", "assertr", "caret", "class", "corrplot", "doParallel", "dplyr", "flextable", "ggplot2", "ggpubr", "knitr", "lme4", "lubridate", "officer", "openxlsx", "pROC", "patchwork", "randomForest", "ranger", "readr", "readxl", "tidyverse", "vip")
to_install <- setdiff(required_pkgs, rownames(installed.packages()))
if (length(to_install)) install.packages(to_install, repos = "https://cloud.r-project.org")
```

---

## â–¶ï¸ How to Reproduce

1. Clone this repository:
   ```bash
   git clone https://github.com/YOUR-USER/YOUR-REPO.git
   cd YOUR-REPO
   ```
2. Open the R Markdown file in RStudio:  
   `Hospital Readmission Prediction for Diabetic Patients _Ugo Raw.Rmd`
3. (Optional) Place your dataset(s) under `data/` and update paths in the Rmd.
4. Click **Knit** to render to HTML/PDF/Word.  
   Or run:
   ```r
   rmarkdown::render("Hospital Readmission Prediction for Diabetic Patients _Ugo Raw.Rmd")
   ```

---

## ðŸ§ª Data & Features

- **Dataset:** Diabetic patient records from multiple U.S. hospitals (1999â€“2008) â€” e.g., the UCI *Diabetes 130â€‘US hospitals* dataset (if applicable).  
- **Target:** 30â€‘day readmission (yes/no).  
- **Typical predictors:** demographics, admission details, comorbidities, medications, labs, length of stay, discharge disposition, prior utilization, and derived features (ratios/flags).  
- **Preâ€‘processing:** missingâ€‘value handling, outlier treatment, type coercion (factors vs numeric), data cleaning (e.g., `janitor::clean_names()`), train/test split with `set.seed(...)` for reproducibility.

### Class imbalance
When positive class is rare, consider:
- Stratified train/test split
- Class weights (e.g., `glmnet`, `xgboost`)
- Resampling: upâ€‘sampling, downâ€‘sampling, or SMOTE (`DMwR2::SMOTE()`)

---

## ðŸ“ Statistical & ML Methods (Direct Explanation)

### Statistical framing
- **Univariate screening:** tâ€‘tests / ANOVA for numeric features and chiâ€‘squared tests for categorical features to identify variables associated with readmission.
- **Logistic regression (baseline):** interpretable oddsâ€‘ratio estimates; check multicollinearity (VIF), linearly separable effects, interaction terms as needed.
- **Model diagnostics:** residual analysis, calibration (e.g., calibration curve, Brier score), and threshold analysis.

### Machine learning models
- **Random Forest:** nonâ€‘linear interactions, robust to noise; tune trees (`ntree`), depth, and `mtry` via crossâ€‘validation.
- **XGBoost:** gradient boosting on decision trees; tune `eta`, `max_depth`, `min_child_weight`, `subsample`, `colsample_bytree`, `lambda`, `alpha`, `nrounds` with kâ€‘fold CV.
- **Regularized GLM (optional):** LASSO / Elastic Net via `glmnet` for embedded feature selection.

### Validation strategy
- **Train/test split** with fixed `set.seed(...)` for reproducibility.
- **kâ€‘fold crossâ€‘validation** for tuning hyperparameters.
- **Threshold selection:** based on precisionâ€‘recall tradeâ€‘offs and cost sensitivity (e.g., maximize F1 or set recall â‰¥ target).

### Evaluation metrics
- **ROCâ€‘AUC:** overall ranking performance.
- **Precisionâ€“Recall curve & AUC:** preferred for imbalanced targets; emphasizes positive class.
- **Sensitivity, Specificity, Precision, Recall, F1â€‘score.**
- **Confusion matrix** at selected threshold(s).
- **Calibration** (reliability) to ensure predicted probabilities are meaningful.

### Explainability
- **Global:** permutation/GINI importances (RF), gain/cover (XGB).
- **Local (optional):** coefficients for logistic regression; consider partialâ€‘dependence profiles or accumulated local effects if added later.

---

## ðŸ“Š Key Outputs

The Rmd renders and/or saves:
- ROC and PR curves comparing models
- Confusion matrices & classification reports
- Feature importance plots
- Calibration plots (if enabled)
- Exported artifacts (e.g., `models/`, `figs/`, `reports/`)

---

## ðŸ§¾ Reproducibility

- Set random seeds with `set.seed(123)` (replace 123 with your chosen seed).
- Document data provenance; avoid committing sensitive data.
- Record package versions: `sessionInfo()` output in the report.

---

## ðŸ§  Interpreting Results (What to look for)

- Compare ROCâ€‘AUC and PRâ€‘AUC across models; for imbalanced data, **PRâ€‘AUC differences are more informative**.
- Inspect feature importances and logistic odds ratios; do they align with clinical expectations?
- Evaluate calibration; if poorly calibrated, consider Platt scaling or isotonic regression.
- Perform error analysis: which subgroups are most misclassified?

---

## ðŸ“Ž How to Cite

If you use this code or report, please cite the repository and the underlying dataset (e.g., UCI Diabetes 130â€‘US hospitals). Add formal references in `docs/REFERENCES.md` as needed.

---

## ðŸ“„ License

Specify a license (e.g., MIT) in `LICENSE` to clarify usage permissions.

---

## ðŸ¤ Contributing

Issues and pull requests are welcome. Please open a discussion before major changes.

---

## ðŸ—’ Notes

- This README is autoâ€‘generated based on your Rmd; adjust dataset details and paths where needed.
